{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vorbereitung: Laden der nötigen Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys   #erlaubt Begriff an best. Stelle einzufügen\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select  #erlaubt Pulldownmenus zu operieren\n",
    "\n",
    "import time #um bei Selenium Zeitpausen einzubauen, damit die Website laden kann\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "#Das hier sind Imports für NetworkX\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Scrapen der Website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zugriff auf Website:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path=\"/usr/local/bin/chromedriver\")\n",
    "driver.get(\"https://www.gemeinderat-zuerich.ch/geschaefte\")\n",
    "\n",
    "#Diese Sleeps braucht es, weil der Browser sonst vom Tempo überfordert ist. \n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein einfaches **Interface, um Geschäftstyp und Jahr auzuwählen**. (Wurde nötig, weil Scraper manchmal unterbrochen wurde. So muss man nicht jedes Mal von vorne anfangen.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geben Sie die Nummer der gewünschten Geschäftsart ein (1 = Motion, 2 = Postulat, 3 = Interpellation, 4 = Schriftliche Anfrage): 1\n",
      "Sie haben Motion gewählt.\n",
      "Geben Sie das gewünschte Jahr ein (0 = alle Jahre): 1998\n",
      "Sie haben das Jahr 1998 gewählt.\n"
     ]
    }
   ],
   "source": [
    "#mit while True baue ich einen Loop, der so lange läuft, bis ein gültiger Wert eingegeben wurde\n",
    "while True:\n",
    "    typ_geschaeft = input(\"Geben Sie die Nummer der gewünschten Geschäftsart ein (1 = Motion, 2 = Postulat, 3 = Interpellation, 4 = Schriftliche Anfrage): \")\n",
    "    typ_geschaeft = int(typ_geschaeft)\n",
    "    \n",
    "    if typ_geschaeft in range (1,5):\n",
    "        if typ_geschaeft == 1:\n",
    "            print(\"Sie haben Motion gewählt.\")\n",
    "        elif typ_geschaeft == 2:\n",
    "            print(\"Sie haben Postulat gewählt.\")\n",
    "        elif typ_geschaeft == 3:\n",
    "            print(\"Sie haben Interpellation gewählt.\")\n",
    "        elif typ_geschaeft == 4:\n",
    "            print(\"Sie haben Schriftliche Anfrage gewählt.\")\n",
    "        break\n",
    "    print(\"Sie haben eine ungültige Zahl eingegegeben. Bitte wiederholen.\")\n",
    "\n",
    "#Dasselbe noch einmal:\n",
    "while True:\n",
    "    jahr_geschaeft = input(\"Geben Sie das gewünschte Jahr ein (0 = alle Jahre): \")\n",
    "    jahr_geschaeft = int(jahr_geschaeft)\n",
    "    \n",
    "    if jahr_geschaeft in range (1970,2020):\n",
    "        print(\"Sie haben das Jahr \"+str(jahr_geschaeft)+\" gewählt.\")\n",
    "        break\n",
    "    elif jahr_geschaeft == 0:\n",
    "        print(\"Sie haben alle verfügbaren Jahre gewählt.\")\n",
    "        break\n",
    "    print(\"Sie haben eine ungültige Zahl eingegegeben. Bitte wiederholen.\")\n",
    "\n",
    "#Hier wird die URL entsprechend der Eingaben zusammengefügt:\n",
    "if jahr_geschaeft == 0:\n",
    "    url = \"https://www.gemeinderat-zuerich.ch/geschaefte/#!geschaeftsartId=\"+str(typ_geschaeft)+\"&activePage=\"\n",
    "    driver.get(url+\"1\")\n",
    "else:\n",
    "    url = \"https://www.gemeinderat-zuerich.ch/geschaefte/#!geschaeftsartId=\"+str(typ_geschaeft)+\"&jahr=\"+str(jahr_geschaeft)+\"&activePage=\"\n",
    "    driver.get(url+\"\")\n",
    "\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier ermittle ich die **Anzahl der Durchgänge**, die für meinen Loop nötig sind. Diesen Wert ermittle ich, indem ich auf der Website die Zahl \"Liste der Geschäfte\" ansteuere und durch 10 teile (weil: 10 geschäfte pro Seite). Achtung: Man muss natürlich aufrunden, damit es auch die allerletzte Seite mitnimmt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = driver.page_source.encode('utf-8')\n",
    "soup1 = BeautifulSoup(page, 'html.parser')\n",
    "span = soup1.find_all(\"span\")\n",
    "treffer = int(span[85].text)\n",
    "\n",
    "#Hier wird mit ceil konsequent aufgerundet\n",
    "seitenzahl = int(np.ceil(treffer/10)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Der Scraping-Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seite in range(1,seitenzahl+1):\n",
    "    \n",
    "    driver.get(url+str(seite))\n",
    "    time.sleep(3)\n",
    "        \n",
    "    #Hier finde ich heraus, wie oft der Loop pro angesteuerter Seite stattfinden muss:\n",
    "    anzahl_geschaefte = len(driver.find_elements_by_class_name(\"tableDataRow\"))\n",
    "\n",
    "    #Jedes Geschäft auf der aktuellen Seite ansteuern und als htm-File im Ordner \"data\" speichern\n",
    "    for einzelgeschaeft in range(0,anzahl_geschaefte): \n",
    "        time.sleep(1) \n",
    "        \n",
    "        geschaefte = driver.find_elements_by_class_name(\"tableDataRow\")\n",
    "        geschaefte[einzelgeschaeft].click()\n",
    "    \n",
    "        page = driver.page_source.encode('utf-8')\n",
    "    \n",
    "        #Hier hole ich die Geschäftsnummer raus und säubere sie vom \"/\", damit ich sie als File-Titel verwenden kann.\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "        nummer = soup.find_all(\"span\")[2].text\n",
    "        nummer = nummer.replace(\"/\",\"_\")\n",
    "    \n",
    "        with open(\"data/geschaeft\"+nummer+\".htm\", \"wb+\") as file:\n",
    "            file.write(page)\n",
    "            file.close()\n",
    "    \n",
    "        #Jetzt gehe ich zurück zur Übersichtsseite und lege eine kurze Pause ein, weil sonst Click z.T. nicht geht. \n",
    "        driver.back()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Auslesen der Daten und speichern in Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Option: Sämtliche Vorstösse auslesen\n",
    "Hier mache ich zum Vergleich einen vereinfachten Dataframe. Das ist eine **reine Kontrollmassnahme**: Es geht nur darum, die Gesamtzahl aller Vorstösse pro Legislatur zu kennen, damit ich  vergleichen kann, ob eine allfällige Zunahme bei den parteiübergreifenden Vorstössen nicht mit einer generellen Zunahme zu erklären ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7026/7026 [05:02<00:00, 23.22it/s]\n"
     ]
    }
   ],
   "source": [
    "#Zuvor habe ich alle Geschäfte manuell in einem Ordner zusammengefügt.\n",
    "files = os.listdir(\"alle_geschaefte\")\n",
    "df_list = []\n",
    "\n",
    "for file in tqdm(files): \n",
    "    \n",
    "    #Hier schliesse ich fehlerhafte Files aus (bei diesen kommt der Begriff \"geschaeft\" im Name nicht vor).\n",
    "    if \"geschaeft\" in file: \n",
    "        geschaeft = open(\"alle_geschaefte/\"+ file, \"r\", encoding = \"utf-8\")\n",
    "        text = geschaeft.read()\n",
    "        soup = BeautifulSoup(text, \"html.parser\")\n",
    "        \n",
    "        #Geschäftsnummer rauslesen\n",
    "        geschaeft_nr = soup.find_all(\"div\")[22].find_all(\"span\")[1].text\n",
    "        \n",
    "        #Datum rauslesen\n",
    "        regex = r\"((?<=\\svom\\s)\\d*\\.\\d*\\.\\s*\\d*)\"\n",
    "        datum = re.findall(regex, str(soup))[0]\n",
    "                \n",
    "        mini_dict = {\n",
    "            \"Datum\" : datum,\n",
    "            \"Geschäft\" : geschaeft_nr}\n",
    "        df_list.append(mini_dict)\n",
    "\n",
    "df_alle = pd.DataFrame(df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fehlerkorrektur 1:** Bei folgenden Positionen stimmt mit dem Datum etwas Grundsätzliches nicht, weshalb wir es mit einem annäherungsweisen Datum aufgrund der Geschäftnummer ersetzen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fehlerliste = [\"29.01.20\",\"08.01.20\",\"18.12.19\"]\n",
    "\n",
    "for fehler in fehlerliste:\n",
    "    fehlerposition = df_alle[df_alle[\"Datum\"] == fehler].index.tolist()\n",
    "    for zeile in fehlerposition:\n",
    "        Jahr = df_alle.loc[zeile, \"Geschäft\"].split(\"/\")[0]\n",
    "        Ersatzdatum = \"31.12.\" + Jahr\n",
    "        df_alle.loc[zeile, \"Datum\"] = df_alle.loc[zeile, \"Datum\"].replace(fehler, Ersatzdatum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fehlerkorrektur 2:** Hier korrigieren wir zwei weitere Fehler, bei denen die Daten zwar stimmen, aber falsch formatiert sind (Leerschläge, zweistellige Jahreszahlen)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_laenge = len(df_alle)\n",
    "for zeile in range(0, df_laenge-1):\n",
    "    \n",
    "    #Hier hole ich jene Daten raus, die nur eine zweistellige Jahreszahl haben und vervollständige sie:\n",
    "    if df_alle.loc[zeile,\"Datum\"][-3:-2] == \".\":\n",
    "        if df_alle.loc[zeile,\"Datum\"][-2:] >= \"80\":\n",
    "            df_alle.loc[zeile,\"Datum\"] = df_alle.loc[zeile,\"Datum\"][:-2]+\"19\"+df_alle.loc[zeile,\"Datum\"][-2:]\n",
    "        if df_alle.loc[zeile,\"Datum\"][-2:] <= \"21\":\n",
    "            df_alle.loc[zeile,\"Datum\"] = df_alle.loc[zeile,\"Datum\"][:-2]+\"20\"+df_alle.loc[zeile,\"Datum\"][-2:]   \n",
    "    \n",
    "    #Hier hole ich jene Daten raus, die einen Leerschlag drin haben und lösche ihn raus:\n",
    "    if df_alle.loc[zeile,\"Datum\"][-3:-2] == \" \":\n",
    "        df_alle.loc[zeile,\"Datum\"] = df_alle.loc[zeile,\"Datum\"][:-3]+df_alle.loc[zeile,\"Datum\"][-2:]\n",
    "        \n",
    "    #Hier hole ich jene Daten mit vierstelligen Jahreszahlen raus, die einen Leerschlag davor haben und lösche ihn:\n",
    "    if df_alle.loc[zeile,\"Datum\"][-5:-4] == \" \":\n",
    "        df_alle.loc[zeile,\"Datum\"] = df_alle.loc[zeile,\"Datum\"][:-5]+df_alle.loc[zeile,\"Datum\"][-4:]\n",
    "    \n",
    "    #Hier hole ich jene Daten raus, die zu kurz sind, weil die Jahreszahl ganz fehlt, und vervollständige sie:\n",
    "    if len(df_alle.loc[zeile,\"Datum\"]) == 6:\n",
    "        Jahr = df_alle.loc[zeile, \"Geschäft\"].split(\"/\")[0]\n",
    "        df_alle.loc[zeile,\"Datum\"] = df_alle.loc[zeile,\"Datum\"]+Jahr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt sind alle Fehler weg, und ich kann die Daten ins Datetime-Format übersetzen und zum Index machen: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geschäft</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datum</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-06-27</th>\n",
       "      <td>2001/362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-04-05</th>\n",
       "      <td>2000/171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-09-12</th>\n",
       "      <td>2007/496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-14</th>\n",
       "      <td>2012/99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-10-27</th>\n",
       "      <td>2004/555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Geschäft\n",
       "Datum               \n",
       "2001-06-27  2001/362\n",
       "2000-04-05  2000/171\n",
       "2007-09-12  2007/496\n",
       "2012-03-14   2012/99\n",
       "2004-10-27  2004/555"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_alle[\"Datum\"] = pd.to_datetime(df_alle['Datum'], format='%d.%m.%Y')\n",
    "df_alle = df_alle.set_index(\"Datum\")\n",
    "df_alle.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt kann man für die Statistik die **Zahl der Vorstösse pro Legislatur** messen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1990-94: 18\n",
      "1994-98: 179\n",
      "1998-02: 1362\n",
      "2002-06: 1386\n",
      "2006-10: 1427\n",
      "2010-14: 1106\n",
      "2014-18: 981\n",
      "2018-22: 561\n"
     ]
    }
   ],
   "source": [
    "df_1990 = df_alle[\"1990-05-15\":\"1994-05-14\"]\n",
    "df_1994 = df_alle[\"1994-05-15\":\"1998-05-14\"]\n",
    "df_1998 = df_alle[\"1998-05-15\":\"2002-05-14\"]\n",
    "df_2002 = df_alle[\"2002-05-15\":\"2006-05-14\"]\n",
    "df_2006 = df_alle[\"2006-05-15\":\"2010-05-14\"]\n",
    "df_2010 = df_alle[\"2010-05-15\":\"2014-05-14\"]\n",
    "df_2014 = df_alle[\"2014-05-15\":\"2018-05-14\"]\n",
    "df_2018 = df_alle[\"2018-05-15\":\"2022-05-14\"]\n",
    "\n",
    "print(\"1990-94: \"+str(len(df_1990)))\n",
    "print(\"1994-98: \"+str(len(df_1994)))\n",
    "print(\"1998-02: \"+str(len(df_1998)))\n",
    "print(\"2002-06: \"+str(len(df_2002)))\n",
    "print(\"2006-10: \"+str(len(df_2006)))\n",
    "print(\"2010-14: \"+str(len(df_2010)))\n",
    "print(\"2014-18: \"+str(len(df_2014)))\n",
    "print(\"2018-22: \"+str(len(df_2018)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Option: Parteiübergreifende Vorstösse auslesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7026/7026 [05:52<00:00, 19.92it/s]\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(\"alle_geschaefte\")\n",
    "df_list = []\n",
    "\n",
    "for file in tqdm(files): \n",
    "    \n",
    "    #Hier schliesse ich fehlerhafte Files aus (bei diesen kommt der Begriff \"geschaeft\" im Name nicht vor).\n",
    "    if \"geschaeft\" in file:\n",
    "        geschaeft = open(\"alle_geschaefte/\"+ file, \"r\", encoding = \"utf-8\")\n",
    "        text = geschaeft.read()\n",
    "        soup = BeautifulSoup(text, \"html.parser\")\n",
    "    \n",
    "        #Jetzt filtere ich jene Vorstösse raus, die mehrere Einreichende haben:\n",
    "        einreichende = soup.find_all(\"div\")[24].find_all(\"a\")\n",
    "        if len(einreichende) > 1: \n",
    "            \n",
    "            #Jetzt filtere ich jene raus, die überhaupt einen Namen drin haben (Erkennungsmerkmal sind Klammern):\n",
    "            einreichender1 = einreichende[0].text.strip()\n",
    "            if \"(\" and \")\" in einreichender1:\n",
    "                \n",
    "                #Hier frage ich nun die gesuchten Daten ab:\n",
    "                name1 = einreichender1.split(\" (\")[0]\n",
    "                partei1 = einreichender1.split(\" (\")[1][:-1]\n",
    "                \n",
    "                einreichender2 = einreichende[1].text.strip()\n",
    "                name2 = einreichender2.split(\" (\")[0]\n",
    "                partei2 = einreichender2.split(\" (\")[1][:-1]\n",
    "                \n",
    "                geschaeft_nr = soup.find_all(\"div\")[22].find_all(\"span\")[1].text\n",
    "                \n",
    "                regex = r\"((?<=\\svom\\s)\\d*\\.\\d*\\.\\s*\\d*)\"\n",
    "                datum = re.findall(regex, str(soup))[0].replace(\" \", \"\")\n",
    "                \n",
    "                try: \n",
    "                    regex_dep = r\"((?<=Zuständiges Departement).*\\n*.*)\"\n",
    "                    dep_fragment = re.findall(regex_dep, str(soup))[0]\n",
    "                    soup_dep = BeautifulSoup(dep_fragment, \"html.parser\")\n",
    "                    departement = soup_dep.text[1:]\n",
    "\n",
    "                except: \n",
    "                    departement = \"\"\n",
    "                            \n",
    "                #Zum Schluss: Wir wollen nur jene in unserem Mini-Dict haben mit unterschiedlichen Parteien:\n",
    "                if partei1 != partei2:\n",
    "                    mini_dict = {\n",
    "                        \"Datum\" : datum,\n",
    "                        \"Geschäft\" : geschaeft_nr,\n",
    "                        \"Einreichender 1\" : name1,\n",
    "                        \"Partei 1\" : partei1,\n",
    "                        \"Einreichender 2\" : name2,\n",
    "                        \"Partei 2\" : partei2,\n",
    "                        \"Departement\" : departement\n",
    "                    }\n",
    "                    df_list.append(mini_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datum</th>\n",
       "      <th>Geschäft</th>\n",
       "      <th>Einreichender 1</th>\n",
       "      <th>Partei 1</th>\n",
       "      <th>Einreichender 2</th>\n",
       "      <th>Partei 2</th>\n",
       "      <th>Departement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.11.2009</td>\n",
       "      <td>2009/562</td>\n",
       "      <td>Kurt Hüssy</td>\n",
       "      <td>SVP</td>\n",
       "      <td>Peter Anderegg</td>\n",
       "      <td>EVP</td>\n",
       "      <td>Polizeidepartement (PD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08.01.2020</td>\n",
       "      <td>2020/2</td>\n",
       "      <td>Marcel Bührig</td>\n",
       "      <td>Grüne</td>\n",
       "      <td>Natascha Wey</td>\n",
       "      <td>SP</td>\n",
       "      <td>Präsidialdepartement (PRD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.09.2011</td>\n",
       "      <td>2011/362</td>\n",
       "      <td>Alecs Recher</td>\n",
       "      <td>AL</td>\n",
       "      <td>Maleica Landolt</td>\n",
       "      <td>GLP</td>\n",
       "      <td>Finanzdepartement (FD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.10.2004</td>\n",
       "      <td>2004/541</td>\n",
       "      <td>Niklaus Scherr</td>\n",
       "      <td>AL</td>\n",
       "      <td>Kurt Maeder</td>\n",
       "      <td>CVP</td>\n",
       "      <td>Hochbaudepartement (HBD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.01.20</td>\n",
       "      <td>1998/191</td>\n",
       "      <td>Rolf Walther</td>\n",
       "      <td>FDP</td>\n",
       "      <td>Jürg Liebermann</td>\n",
       "      <td></td>\n",
       "      <td>Finanzdepartement (FD)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Datum  Geschäft Einreichender 1 Partei 1  Einreichender 2 Partei 2  \\\n",
       "0  25.11.2009  2009/562      Kurt Hüssy      SVP   Peter Anderegg      EVP   \n",
       "1  08.01.2020    2020/2   Marcel Bührig    Grüne     Natascha Wey       SP   \n",
       "2  28.09.2011  2011/362    Alecs Recher       AL  Maleica Landolt      GLP   \n",
       "3  20.10.2004  2004/541  Niklaus Scherr       AL      Kurt Maeder      CVP   \n",
       "4    29.01.20  1998/191    Rolf Walther      FDP  Jürg Liebermann            \n",
       "\n",
       "                  Departement  \n",
       "0     Polizeidepartement (PD)  \n",
       "1  Präsidialdepartement (PRD)  \n",
       "2      Finanzdepartement (FD)  \n",
       "3    Hochbaudepartement (HBD)  \n",
       "4      Finanzdepartement (FD)  "
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(df_list)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bereinigen von Daten**, bei denen die Parteiangaben fehlen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zum Reparieren mache ich ein Dict, in dem die fehelnden Parteiabgaben zugeordnet werden (manuell recherchiert):\n",
    "Reparatur_dict = {\"Gregor Bucher\":\"Grüne\",\n",
    "                  \"Andreas Ammann\":\"SP\",\n",
    "                  \"Urs Rechsteiner\":\"CVP\",\n",
    "                  \"Andreas J. Schlegel\":\"FDP\",\n",
    "                  \"Jürg Liebermann\":\"FDP\",\n",
    "                  \"Peter Marti\":\"FDP\",\n",
    "                  \"Fakir Atalay\":\"SP\",\n",
    "                  \"Anton Stäbler\":\"CVP\",\n",
    "                  \"Placidus Maissen\":\"CVP\",\n",
    "                  \"Salomon Browar\":\"Grüne\",\n",
    "                  \"Monika Piesbergen\":\"FDP\",\n",
    "                  \"Hanna Lienhard\":\"FDP\",\n",
    "                  \"Urs Lauffer\":\"FDP\",\n",
    "                  \"Esther Ponti-Weder\":\"CVP\"}\n",
    "\n",
    "#Hier definiere ich eine Funktion, die für jede eingegebene Person der Parteinamen ausspuckt:\n",
    "def Reparatur(Person):\n",
    "    return Reparatur_dict[Person]\n",
    "\n",
    "#Jetzt mache ich eine Liste, die die Indexzahlen aller fehlerhaften Positionen für den \"Einreichenden 1\" enthält:\n",
    "fehlerposition1 = df[df[\"Partei 1\"] == \"\"][\"Einreichender 1\"].index.tolist()\n",
    "\n",
    "#Hier steuere ich für in jeder fehlerhaften Zeile die leere Partei-Zelle an, und fülle diese mit dem richtigen Wert.\n",
    "#Die Leerstelle \"\" wird ersetzt duch das, was die Funktion ausspuckt.\n",
    "for zeile in fehlerposition1:\n",
    "    df.loc[zeile, 'Partei 1'] = df.loc[zeile, 'Partei 1'].replace(\"\", Reparatur(df.loc[zeile, \"Einreichender 1\"]))\n",
    "    \n",
    "#Genau das Gleiche wird nun für die Spalte \"Einreichender 2\" wiederholt:    \n",
    "fehlerposition2 = df[df[\"Partei 2\"] == \"\"][\"Einreichender 2\"].index.tolist()\n",
    "for zeile in fehlerposition2:\n",
    "    df.loc[zeile, 'Partei 2'] = df.loc[zeile, 'Partei 2'].replace(\"\", Reparatur(df.loc[zeile, \"Einreichender 2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bereinigung nach der Reparatur:** Durch die Reparatur sind nachträglich Paare der gleichen Partei entstanden – die muss ich rausfiltern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "for zeile in range(0, len(df)-1):\n",
    "    if df.loc[zeile, \"Partei 1\"] == df.loc[zeile, \"Partei 2\"]:\n",
    "        df.drop(zeile, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1. Anzahl Vorstösse pro Legislatur zählen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dazu erneut erst die fehlerhaften Timestamps korrigieren. **Fehlerkorrektur 1:** Bei folgenden Positionen stimmt mit dem Datum etwas Grundsätzliches nicht, weshalb wir es mit einem annäherungsweisen Datum aufgrund der Geschäftnummer ersetzen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "fehlerliste = [\"29.01.20\",\"08.01.20\",\"18.12.19\"]\n",
    "\n",
    "for fehler in fehlerliste:\n",
    "    fehlerposition = df[df[\"Datum\"] == fehler].index.tolist()\n",
    "    for zeile in fehlerposition:\n",
    "        Jahr = df.loc[zeile, \"Geschäft\"].split(\"/\")[0]\n",
    "        Ersatzdatum = \"31.12.\" + Jahr\n",
    "        df.loc[zeile, \"Datum\"] = df.loc[zeile, \"Datum\"].replace(fehler, Ersatzdatum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fehlerkorrektur 2:** Hier korrigieren wir zwei weitere Fehler, bei denen die Daten zwar stimmen, aber falsch formatiert sind (Leerschläge, zweistellige Jahreszahlen). **Achtung:** Weil ich zuvor (bei der Bereinigung nach der Reparatur) ein paar Zeilen gelöscht habe, muss ich zuerst den Index neu setzen, weil sonst der folgende Loop, der durch alle Zeilen läuft, einen Fehler produziert!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hier setze ich den Index neu und lösche den alten:\n",
    "df = df.reset_index()\n",
    "df = df.drop(columns=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jetzt kann ich durch den Dataframe iterieren und fehlerhafte Daten ersetzen.\n",
    "df_laenge = len(df)\n",
    "for zeile in range(0, df_laenge-1):\n",
    "    \n",
    "    #Hier hole ich jene Daten raus, die nur eine zweistellige Jahreszahl haben und vervollständige sie:\n",
    "    if df.loc[zeile,\"Datum\"][-3:-2] == \".\":\n",
    "        if df.loc[zeile,\"Datum\"][-2:] >= \"80\":\n",
    "            df.loc[zeile,\"Datum\"] = df.loc[zeile,\"Datum\"][:-2]+\"19\"+df.loc[zeile,\"Datum\"][-2:]\n",
    "        if df.loc[zeile,\"Datum\"][-2:] <= \"21\":\n",
    "            df.loc[zeile,\"Datum\"] = df.loc[zeile,\"Datum\"][:-2]+\"20\"+df.loc[zeile,\"Datum\"][-2:]   \n",
    "    \n",
    "    #Hier hole ich jene Daten raus, die einen Leerschlag drin haben und lösche ihn raus:\n",
    "    if df.loc[zeile,\"Datum\"][-3:-2] == \" \":\n",
    "        df.loc[zeile,\"Datum\"] = df.loc[zeile,\"Datum\"][:-3]+df.loc[zeile,\"Datum\"][-2:]\n",
    "        \n",
    "    #Hier hole ich jene Daten mit vierstelligen Jahreszahlen raus, die einen Leerschlag davor haben und lösche ihn:\n",
    "    if df.loc[zeile,\"Datum\"][-5:-4] == \" \":\n",
    "        df.loc[zeile,\"Datum\"] = df.loc[zeile,\"Datum\"][:-5]+df.loc[zeile,\"Datum\"][-4:]\n",
    "    \n",
    "    #Hier hole ich jene Daten raus, die zu kurz sind, weil die Jahreszahl ganz fehlt, und vervollständige sie:\n",
    "    if len(df.loc[zeile,\"Datum\"]) == 6:\n",
    "        Jahr = df.loc[zeile, \"Geschäft\"].split(\"/\")[0]\n",
    "        df.loc[zeile,\"Datum\"] = df.loc[zeile,\"Datum\"]+Jahr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt, wo alle Fehler behoben sind,  kann die Daten ins Datetime-Format übersetzen und zum Index eines neuen Dataframes machen (das Original  muss ich belassen ich, weil ich das  später nochmals mit Nummern-Index brauche).\n",
    "\n",
    "Dann kann ich für die Statistik die **Zahl der parteiübergreifenden Vorstösse pro Legislatur** zählen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1990-94: 3\n",
      "1994-98: 16\n",
      "1998-02: 133\n",
      "2002-06: 242\n",
      "2006-10: 233\n",
      "2010-14: 162\n",
      "2014-18: 197\n",
      "2018-22: 129\n"
     ]
    }
   ],
   "source": [
    "df[\"Datum\"] = pd.to_datetime(df['Datum'], format='%d.%m.%Y')\n",
    "df_time = df.set_index(\"Datum\")\n",
    "\n",
    "df_1990 = df_time[\"1990-05-15\":\"1994-05-14\"]\n",
    "df_1994 = df_time[\"1994-05-15\":\"1998-05-14\"]\n",
    "df_1998 = df_time[\"1998-05-15\":\"2002-05-14\"]\n",
    "df_2002 = df_time[\"2002-05-15\":\"2006-05-14\"]\n",
    "df_2006 = df_time[\"2006-05-15\":\"2010-05-14\"]\n",
    "df_2010 = df_time[\"2010-05-15\":\"2014-05-14\"]\n",
    "df_2014 = df_time[\"2014-05-15\":\"2018-05-14\"]\n",
    "df_2018 = df_time[\"2018-05-15\":\"2022-05-14\"]\n",
    "\n",
    "print(\"1990-94: \"+str(len(df_1990)))\n",
    "print(\"1994-98: \"+str(len(df_1994)))\n",
    "print(\"1998-02: \"+str(len(df_1998)))\n",
    "print(\"2002-06: \"+str(len(df_2002)))\n",
    "print(\"2006-10: \"+str(len(df_2006)))\n",
    "print(\"2010-14: \"+str(len(df_2010)))\n",
    "print(\"2014-18: \"+str(len(df_2014)))\n",
    "print(\"2018-22: \"+str(len(df_2018)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2. Parteipaare pro Legislatur auswerten\n",
    "Hier habe ich eine Abfrage gebaut, die von der gewünschten Legislatur die Parteipaare nach Häufigkeit ausspuckt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bitte Legislaturstart eingeben:2018\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parteipaar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Grüne / SP</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLP / SP</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL / Grüne</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FDP / SP</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL / SP</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FDP / GLP</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FDP / SVP</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLP / Grüne</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FDP / Grüne</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP / SVP</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL / GLP</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL / EVP</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL / FDP</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grüne / SVP</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EVP / FDP</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLP / SVP</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL / SVP</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EVP / GLP</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Parteipaar\n",
       "Grüne / SP           31\n",
       "GLP / SP             20\n",
       "AL / Grüne           16\n",
       "FDP / SP             14\n",
       "AL / SP               8\n",
       "FDP / GLP             7\n",
       "FDP / SVP             6\n",
       "GLP / Grüne           5\n",
       "FDP / Grüne           4\n",
       "SP / SVP              3\n",
       "AL / GLP              3\n",
       "AL / EVP              2\n",
       "AL / FDP              2\n",
       "Grüne / SVP           2\n",
       "EVP / FDP             2\n",
       "GLP / SVP             1\n",
       "AL / SVP              1\n",
       "EVP / GLP             1"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hier mache ich eine Liste aus den oben gebauten Dataframes nach Legislatur.\n",
    "dataframe_list = [df_1994, df_1998, df_2002, df_2006, df_2010, df_2014, df_2018]\n",
    "\n",
    "#Hier kann ich per Abfrage auf einen einzelnen dieser Legislatur-Frames zugreifen und ihn auswerten.\n",
    "legislatur = input(\"Bitte Legislaturstart eingeben:\")\n",
    "legislatur = int(legislatur)\n",
    "if legislatur == 1994:\n",
    "    frame = dataframe_list[0]\n",
    "elif legislatur == 1998:\n",
    "    frame = dataframe_list[1]\n",
    "elif legislatur == 2002:\n",
    "    frame = dataframe_list[2]\n",
    "elif legislatur == 2006:\n",
    "    frame = dataframe_list[3]\n",
    "elif legislatur == 2010:\n",
    "    frame = dataframe_list[4]\n",
    "elif legislatur == 2014:\n",
    "    frame = dataframe_list[5]\n",
    "elif legislatur == 2018:\n",
    "    frame = dataframe_list[6]\n",
    "else: \n",
    "    print(\"ungültige Legislatur eingegeben!\")\n",
    "    \n",
    "#ein neuer Index ist wie immer nötig, um durch den Frame zu iterieren.\n",
    "frame = frame.reset_index()\n",
    "\n",
    "#Der ord-Befehl hilf hier, indem er eine Zahl für die Anfangsbuchstaben der Parteien abfragt, damit wir alle Paare nur einmal erfassen:\n",
    "for element in range(0, len(frame)-1):\n",
    "    if ord(frame.loc[element,\"Partei 1\"][0]) < ord(frame.loc[element,\"Partei 2\"][0]):\n",
    "        frame.loc[element, \"Parteipaar\"] = frame.loc[element,\"Partei 1\"] + \" / \"+ frame.loc[element,\"Partei 2\"]\n",
    "    elif ord(frame.loc[element,\"Partei 1\"][0]) > ord(frame.loc[element,\"Partei 2\"][0]):\n",
    "        frame.loc[element, \"Parteipaar\"] = frame.loc[element,\"Partei 2\"] + \" / \"+ frame.loc[element,\"Partei 1\"]\n",
    "        \n",
    "    #Manche Parteien haben den gleichen Anfangsbuchstaben, bei denen schaue ich auch den zweiten an:    \n",
    "    else:\n",
    "        if ord(frame.loc[element,\"Partei 1\"][1]) < ord(frame.loc[element,\"Partei 2\"][1]):\n",
    "            frame.loc[element, \"Parteipaar\"] = frame.loc[element,\"Partei 1\"] + \" / \"+ frame.loc[element,\"Partei 2\"]\n",
    "        else:\n",
    "            frame.loc[element, \"Parteipaar\"] = frame.loc[element,\"Partei 2\"] + \" / \"+ frame.loc[element,\"Partei 1\"]\n",
    "            \n",
    "frame[\"Parteipaar\"].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3. Aspeichern als CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ganz zum Schluss wird das gesäuberte Ergebnis **als csv-File gespeichert**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time.to_csv(\"data_csv/Dataframe_bereinigt_parteiuebergreifend.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Option: Blockübergreifende Vorstösse auslesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hier definieren wir die drei Blöcke\n",
    "Block_Links = [\"SP\", \"Grüne\", \"AL\", \"FraP\", \"CSP\"]\n",
    "Block_Mitte = [\"CVP\", \"GLP\", \"EVP\", \"LdU\", \"Parteilos\"]\n",
    "Block_Rechts = [\"FDP\", \"SVP\", \"PFZ\", \"SL\"]\n",
    "\n",
    "for zeile in range(0, len(df)-1):\n",
    "    \n",
    "    #erst müssen wir die fehlende Wert für die Blöcke ergänzen...\n",
    "    if df.loc[zeile, \"Partei 1\"] in Block_Links:\n",
    "        df.loc[zeile, \"Block 1\"] = \"links\"\n",
    "    elif df.loc[zeile, \"Partei 1\"] in Block_Mitte:\n",
    "        df.loc[zeile, \"Block 1\"] = \"mitte\"\n",
    "    else:\n",
    "        df.loc[zeile, \"Block 1\"] = \"rechts\"\n",
    "                    \n",
    "    if df.loc[zeile, \"Partei 2\"] in Block_Links:\n",
    "        df.loc[zeile, \"Block 2\"] = \"links\"\n",
    "    elif df.loc[zeile, \"Partei 2\"] in Block_Mitte:\n",
    "        df.loc[zeile, \"Block 2\"] = \"mitte\"\n",
    "    else:\n",
    "        df.loc[zeile, \"Block 2\"] = \"rechts\"\n",
    "    \n",
    "    #...und dann löschen wir gleiche raus\n",
    "    if df.loc[zeile, \"Block 1\"] == df.loc[zeile, \"Block 2\"]:\n",
    "        #print( df.loc[zeile, \"Block 1\"] + df.loc[zeile, \"Block 2\"])\n",
    "        df.drop(zeile, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Anzahl Vorstösse pro Legislatur zählen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch hier für die Statistik: Die **Zahl der blockübergreifenden Vorstösse pro Legislatur** messen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1990-94: 0\n",
      "1994-98: 7\n",
      "1998-02: 39\n",
      "2002-06: 81\n",
      "2006-10: 95\n",
      "2010-14: 91\n",
      "2014-18: 102\n",
      "2018-22: 67\n"
     ]
    }
   ],
   "source": [
    "df[\"Datum\"] = pd.to_datetime(df['Datum'], format='%d.%m.%Y')\n",
    "df_time = df.set_index(\"Datum\")\n",
    "\n",
    "df_1990 = df_time[\"1990-05-15\":\"1994-05-14\"]\n",
    "df_1994 = df_time[\"1994-05-15\":\"1998-05-14\"]\n",
    "df_1998 = df_time[\"1998-05-15\":\"2002-05-14\"]\n",
    "df_2002 = df_time[\"2002-05-15\":\"2006-05-14\"]\n",
    "df_2006 = df_time[\"2006-05-15\":\"2010-05-14\"]\n",
    "df_2010 = df_time[\"2010-05-15\":\"2014-05-14\"]\n",
    "df_2014 = df_time[\"2014-05-15\":\"2018-05-14\"]\n",
    "df_2018 = df_time[\"2018-05-15\":\"2022-05-14\"]\n",
    "\n",
    "print(\"1990-94: \"+str(len(df_1990)))\n",
    "print(\"1994-98: \"+str(len(df_1994)))\n",
    "print(\"1998-02: \"+str(len(df_1998)))\n",
    "print(\"2002-06: \"+str(len(df_2002)))\n",
    "print(\"2006-10: \"+str(len(df_2006)))\n",
    "print(\"2010-14: \"+str(len(df_2010)))\n",
    "print(\"2014-18: \"+str(len(df_2014)))\n",
    "print(\"2018-22: \"+str(len(df_2018)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2. Aspeichern als CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch hier wird das gesäuberte Ergebnis **als csv-File gespeichert**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time.to_csv(\"data_csv/Dataframe_bereinigt_blockuebergreifend.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Option: Vorstösse von linkem Block mit Mitte / Rechts auslesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zuerst setze ich wieder den Index neu und lösche den alten, damit ich durch die Zeilen iterieren kann:\n",
    "df = df.reset_index()\n",
    "df = df.drop(columns=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier lösche ich Zeilen, in denen weder die eine noch die andere Person zum linken Block gehören: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "for zeile in range(0, len(df)-1):\n",
    "    if df.loc[zeile, \"Block 1\"] != \"links\": \n",
    "        if df.loc[zeile, \"Block 2\"] != \"links\":\n",
    "            df.drop(zeile, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1. Anzahl Vorstösse nach Departement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tiefbau- und Entsorgungsdepartement (TED)                                       110\n",
       "Hochbaudepartement (HBD)                                                         40\n",
       "Präsidialdepartement (PRD)                                                       32\n",
       "Departement der Industriellen Betriebe (DIB)                                     32\n",
       "Polizeidepartement (PD)                                                          31\n",
       "Schul- und Sportdepartement (SSD)                                                31\n",
       "Finanzdepartement (FD)                                                           25\n",
       "Sozialdepartement (SD)                                                           23\n",
       "Sicherheitsdepartement (SID)                                                     20\n",
       "Gesundheits- und Umweltdepartement (GUD)                                         18\n",
       "Hochbaudepartement (HBD), Schul- und Sportdepartement (SSD)                       2\n",
       "Finanzdepartement (FD), Hochbaudepartement (HBD), Präsidialdepartement (PRD)      1\n",
       "Zuteilung ausstehend                                                              1\n",
       "                                                                                  1\n",
       "Name: Departement, dtype: int64"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Departement\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2 Anzahl Vorstösse pro Legislatur zählen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch das kann man für die Statistik zählen: Die **Zahl der Vorstösse zwischen Linken und anderen pro Legislatur**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1990-94: 0\n",
      "1994-98: 4\n",
      "1998-02: 19\n",
      "2002-06: 67\n",
      "2006-10: 75\n",
      "2010-14: 72\n",
      "2014-18: 73\n",
      "2018-22: 57\n"
     ]
    }
   ],
   "source": [
    "df[\"Datum\"] = pd.to_datetime(df['Datum'], format='%d.%m.%Y')\n",
    "df_time = df.set_index(\"Datum\")\n",
    "\n",
    "df_1990 = df_time[\"1990-05-15\":\"1994-05-14\"]\n",
    "df_1994 = df_time[\"1994-05-15\":\"1998-05-14\"]\n",
    "df_1998 = df_time[\"1998-05-15\":\"2002-05-14\"]\n",
    "df_2002 = df_time[\"2002-05-15\":\"2006-05-14\"]\n",
    "df_2006 = df_time[\"2006-05-15\":\"2010-05-14\"]\n",
    "df_2010 = df_time[\"2010-05-15\":\"2014-05-14\"]\n",
    "df_2014 = df_time[\"2014-05-15\":\"2018-05-14\"]\n",
    "df_2018 = df_time[\"2018-05-15\":\"2022-05-14\"]\n",
    "\n",
    "print(\"1990-94: \"+str(len(df_1990)))\n",
    "print(\"1994-98: \"+str(len(df_1994)))\n",
    "print(\"1998-02: \"+str(len(df_1998)))\n",
    "print(\"2002-06: \"+str(len(df_2002)))\n",
    "print(\"2006-10: \"+str(len(df_2006)))\n",
    "print(\"2010-14: \"+str(len(df_2010)))\n",
    "print(\"2014-18: \"+str(len(df_2014)))\n",
    "print(\"2018-22: \"+str(len(df_2018)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.3 Anzahl Links/Rechts-Kooperationen nach Thema zählen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier ein Beispiel für die Legislatur 2018:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Departement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hochbaudepartement (HBD)</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sicherheitsdepartement (SID)</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Schul- und Sportdepartement (SSD)</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tiefbau- und Entsorgungsdepartement (TED)</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sozialdepartement (SD)</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Departement der Industriellen Betriebe (DIB)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Finanzdepartement (FD)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Präsidialdepartement (PRD)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Departement\n",
       "Hochbaudepartement (HBD)                                7\n",
       "Sicherheitsdepartement (SID)                            5\n",
       "Schul- und Sportdepartement (SSD)                       5\n",
       "Tiefbau- und Entsorgungsdepartement (TED)               4\n",
       "Sozialdepartement (SD)                                  2\n",
       "Departement der Industriellen Betriebe (DIB)            1\n",
       "Finanzdepartement (FD)                                  1\n",
       "Präsidialdepartement (PRD)                              1"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2018[(df_2018[\"Block 1\"] == \"rechts\") | (df_2018[\"Block 2\"] == \"rechts\")][\"Departement\"].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018[(df_2018[\"Block 1\"] == \"rechts\") | (df_2018[\"Block 2\"] == \"rechts\")][\"Departement\"].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.4. Aspeichern als CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Und zum Dritten: Das gesäuberte Ergebnis wird **als csv-File gespeichert**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time.to_csv(\"data_csv/Dataframe_bereinigt_linksuebergreifend.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Netzwerke bauen aus Legislaturdaten bauen\n",
    "\n",
    "Weil ichs nicht geschafft habe, in Gephi dynamische Graphs mit Timestamps zu machen, baue ich hier einen Loop, der uns für jede Legislatur ein separates gexf-File baut.\n",
    "\n",
    "Zunächst kann man hier wählen, welcher Datensatz (zuvor gespeichertes CSV-File) geöffnet und verarbeitet werden soll:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bitte Datensatz wählen, der zu Netzwerk verarbeitet werden soll (1 = parteiübergreifende Vorstösse, 2 = blockübergreifende Vorstösse, 3 = Vorstösse von Links mit Mitte / Rechts): 1\n"
     ]
    }
   ],
   "source": [
    "datensatz = input(\"Bitte Datensatz wählen, der zu Netzwerk verarbeitet werden soll (1 = parteiübergreifende Vorstösse, 2 = blockübergreifende Vorstösse, 3 = Vorstösse von Links mit Mitte / Rechts): \")\n",
    "datensatz = int(datensatz)\n",
    "if datensatz == 1:\n",
    "    file = open(\"data_csv/Dataframe_bereinigt_parteiuebergreifend.csv\", mode=\"r\")\n",
    "elif datensatz == 2:\n",
    "    file = open(\"data_csv/Dataframe_bereinigt_blockuebergreifend.csv\", mode=\"r\")\n",
    "elif datensatz == 3:\n",
    "    file = open(\"data_csv/Dataframe_bereinigt_linksuebergreifend.csv\", mode=\"r\")\n",
    "else: \n",
    "    print(\"ungültige Nummer eingegeben!\")\n",
    "\n",
    "df2 = pd.read_csv(file)\n",
    "df2[\"Datum\"] = pd.to_datetime(df2['Datum'], format='%Y.%m.%d')\n",
    "df2 = df2.set_index(\"Datum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weil Netzwerke Legislaturübergreifend keinen Sinn ergeben, splitten wir den Dataframe nach Legislaturen auf und packen diese Sub-Frames in eine Liste, so dass wir sie danach einen nach dem anderen zu Netzwerken verarbeiten und dann abspeichern können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1994 = df2[\"1994-05-15\":\"1998-05-14\"]\n",
    "df_1998 = df2[\"1998-05-15\":\"2002-05-14\"]\n",
    "df_2002 = df2[\"2002-05-15\":\"2006-05-14\"]\n",
    "df_2006 = df2[\"2006-05-15\":\"2010-05-14\"]\n",
    "df_2010 = df2[\"2010-05-15\":\"2014-05-14\"]\n",
    "df_2014 = df2[\"2014-05-15\":\"2018-05-14\"]\n",
    "df_2018 = df2[\"2018-05-15\":\"2022-05-14\"]\n",
    "\n",
    "dataframe_list = [df_1994, df_1998, df_2002, df_2006, df_2010, df_2014, df_2018]\n",
    "\n",
    "#Das ist ein Zähler, den wir im Loop brauchen bei der Benennung der Files:\n",
    "legislatur = 1994"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Und hier entstehen nun die eigentlichen gexf-Netzwerke:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in dataframe_list:\n",
    "    #Wie immer: neuen Index machen, sonst kann man die einzelnen Zeilen nicht ansteuern...\n",
    "    frame.reset_index(inplace = True)\n",
    "    \n",
    "    #Hier wird das Netzwerk definiert\n",
    "    Netz = nx.Graph()\n",
    "\n",
    "    #Hier werden auf jeder Zeile des Frames zwei Knoten zum Netz hinzugefügt, inkl. Parteidaten als Attribute:\n",
    "    for a in range(0,(len(frame)-1)):\n",
    "        Person1 = str(frame.loc[a][\"Einreichender 1\"])\n",
    "        Person2 = str(frame.loc[a][\"Einreichender 2\"])\n",
    "        Partei1 = str(frame.loc[a][\"Partei 1\"])\n",
    "        Partei2 = str(frame.loc[a][\"Partei 2\"])\n",
    "        Netz.add_node(Person1, Partei = Partei1)\n",
    "        Netz.add_node(Person2, Partei = Partei2)\n",
    "\n",
    "    #Als zweites werden die Kntone mit Edges verbunden und mit Timestamp und Departement versehen:\n",
    "    for a in range(0,(len(frame)-1)):\n",
    "        Person1 = str(frame.loc[a][\"Einreichender 1\"])\n",
    "        Person2 = str(frame.loc[a][\"Einreichender 2\"])\n",
    "        date = str(frame.loc[a][\"Datum\"])\n",
    "        Departement = str(frame.loc[a][\"Departement\"])\n",
    "    \n",
    "        #Beziehungen, die bereits vorkommen, werden nicht neu hinzugefügt, sondern gewichtet (weight +1)\n",
    "        if Netz.has_edge(Person1, Person2):\n",
    "            Netz[Person1][Person2][\"weight\"] += 1\n",
    "        else:\n",
    "            Netz.add_edge(Person1, Person2, datum = date, thema = Departement, weight=1)\n",
    "    \n",
    "    #Hier definiere ich ein paar Variablen für die Benennung der gexf-Files:\n",
    "    if datensatz == 1:\n",
    "        kategorie = \"partei\"\n",
    "    elif datensatz == 2:\n",
    "        kategorie = \"block\"\n",
    "    else:\n",
    "        kategorie = \"links\"\n",
    "      \n",
    "    nx.write_gexf(Netz, \"data_gexf/\"+str(legislatur)+\"_Netz_\"+kategorie+\".gexf\")\n",
    "    \n",
    "    legislatur = legislatur + 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Netzwerkanalyse\n",
    "\n",
    "Eine Abfrage, mit der man die gespeicherten Files nach Beliben öffnen und analysieren kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bitte Jahreszahl der zu analysierenden Legislatur eingeben: 2018\n",
      "Bitte Datensatz wählen, der zu Netzwerk verarbeitet werden soll (1 = parteiübergreifende Vorstösse, 2 = blockübergreifende Vorstösse, 3 = Vorstösse von Links mit Mitte / Rechts): 3\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    legislatur = input(\"Bitte Jahreszahl der zu analysierenden Legislatur eingeben: \")\n",
    "    datensatz = input(\"Bitte Datensatz wählen, der zu Netzwerk verarbeitet werden soll (1 = parteiübergreifende Vorstösse, 2 = blockübergreifende Vorstösse, 3 = Vorstösse von Links mit Mitte / Rechts): \")\n",
    "    \n",
    "    try:\n",
    "        if datensatz == 1:\n",
    "            kategorie = \"partei\"\n",
    "        elif datensatz == 2:\n",
    "            kategorie = \"block\"\n",
    "        elif datensatz == 3:\n",
    "            kategorie = \"links\"\n",
    "        \n",
    "        Netz = nx.read_gexf(\"data_gexf/\"+str(legislatur)+\"_Netz_\"+kategorie+\".gexf\")\n",
    "        break\n",
    "        \n",
    "    except:\n",
    "        print(\"Fehlerhafte Inputs. Bitte wiederholen.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier ein paar grundsätzliche **Infos zum gewählten Netz**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 87\n",
      "Number of edges: 100\n",
      "Average degree:   2.2989\n"
     ]
    }
   ],
   "source": [
    "print(nx.info(Netz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdegree = dict(Netz.degree(weight='weight'))\n",
    "degc = nx.degree_centrality(Netz)\n",
    "bet = nx.betweenness_centrality(Netz)\n",
    "clos = nx.closeness_centrality(Netz)\n",
    "\n",
    "#Eigenvector-Centrality funktioniert nicht immer.\n",
    "try: \n",
    "    eig = nx.eigenvector_centrality(Netz)\n",
    "    centrality_measures = {\n",
    "        'degree': degc,\n",
    "        'gew. degree': wdegree,\n",
    "        'betweenness': bet,\n",
    "        'closeness': clos,\n",
    "        \"eigenvector\": eig,\n",
    "    }\n",
    "\n",
    "except:\n",
    "    centrality_measures = {\n",
    "        'degree': degc,\n",
    "        'gew. degree': wdegree,\n",
    "        'betweenness': bet,\n",
    "        'closeness': clos,\n",
    "    }\n",
    "\n",
    "df_analyse = pd.DataFrame(centrality_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Den Analyse-Dataframe kann man beliebig sortieren. Hier die Bedeutung der verschiedenen Werte:\n",
    "- **degree** = Anzahl der Kanten die mit dem Knoten verbunden sind\n",
    "- **gew. degree** = summe der gewichteten Kanten\n",
    "- **betweenness centrality** =  Summe der Anteile aller kürzesten Pfade von x nach y, die durch diesen Knoten laufen\n",
    "- **closeness centrality** = summe der kürzesten Pfade vom Knoten zu allen anderen Knoten \n",
    "- **eigenvector centrality** = gewichtet Knoten basierend auf der Idee, dass Knoten mit hohen Gewichten mehr zur Zentrelität beitragen als Knoten mit niedrigen Gewichten. (Wer mit wichtigen Leuten verbunden ist, ist selbst wichtiger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>degree</th>\n",
       "      <th>gew. degree</th>\n",
       "      <th>betweenness</th>\n",
       "      <th>closeness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Luca Maggi</th>\n",
       "      <td>0.046512</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.036626</td>\n",
       "      <td>0.181927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balz Bürgisser</th>\n",
       "      <td>0.104651</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.245633</td>\n",
       "      <td>0.248728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pascal Lamprecht</th>\n",
       "      <td>0.058140</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.140536</td>\n",
       "      <td>0.252676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Christina Schiller</th>\n",
       "      <td>0.034884</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.061846</td>\n",
       "      <td>0.211543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ezgi Akyol</th>\n",
       "      <td>0.034884</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.024697</td>\n",
       "      <td>0.177862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anjushka Früh</th>\n",
       "      <td>0.046512</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.026995</td>\n",
       "      <td>0.172559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Simone Brander</th>\n",
       "      <td>0.046512</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.053882</td>\n",
       "      <td>0.216580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sebastian Vogel</th>\n",
       "      <td>0.034884</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.072120</td>\n",
       "      <td>0.227409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Guido Hüni</th>\n",
       "      <td>0.046512</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.076605</td>\n",
       "      <td>0.211543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Andri Silberschmidt</th>\n",
       "      <td>0.069767</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.160669</td>\n",
       "      <td>0.248728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       degree  gew. degree  betweenness  closeness\n",
       "Luca Maggi           0.046512         12.0     0.036626   0.181927\n",
       "Balz Bürgisser       0.104651         12.0     0.245633   0.248728\n",
       "Pascal Lamprecht     0.058140          9.0     0.140536   0.252676\n",
       "Christina Schiller   0.034884          8.0     0.061846   0.211543\n",
       "Ezgi Akyol           0.034884          6.0     0.024697   0.177862\n",
       "Anjushka Früh        0.046512          6.0     0.026995   0.172559\n",
       "Simone Brander       0.046512          6.0     0.053882   0.216580\n",
       "Sebastian Vogel      0.034884          6.0     0.072120   0.227409\n",
       "Guido Hüni           0.046512          6.0     0.076605   0.211543\n",
       "Andri Silberschmidt  0.069767          6.0     0.160669   0.248728"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analyse.sort_values(\"gew. degree\", ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
